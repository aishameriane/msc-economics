---
title: "Uhlig - 1997"
author: "Aishameriane Schmidt"
header-includes:
   - \usepackage{bigints}
   - \usepackage[brazil]{babel}
   - \usepackage{graphicx}
   - \usepackage{amsmath}
output: html_document
bibliography: references2.bib
---

# Bayesian Vector Autoregressions with Stochastic Volatility

(Resumão de [@uhlig_1997])

## Resumo

O trabalho propõe uma metodologia bayesiana para vetores autoregressivos com volatilidade estocástica, onde a evolução da matriz de precisão é dada por uma distribuição beta multivariada.

## Introdução

* A abordagem do autor permite que a matriz de precisão seja não-observável com "choques aleatórios" oriundos de uma distribuição beta multivariada;
 - Isso torna possível a interpretação de grandes movimentos abruptos como sendo consequência de uma distribuição com variância aleatória não observável;
* O fato da Wishart e da Beta singulares multivariadas serem conjugadas permite que a integração para a posteriori seja feita de maneira analítica;
  - O que leva a generalização das fórmulas para filtro de Kalman padrão para o problema de filtragem não linear proposto
* Ainda assim, as estimativas para os parâmetros autoregressivos requerem métodos numéricos
  - O trabalho utiliza amostragem por importância
* Existe um modelo univariado, não bayesiano e não autoregressivo proposto por Shephard (1994) cujo modelo de volatilidade estocástica é um caso particular do Uhlig
* A inovação em comparação com outros trabalhos é que o método do Uhlig resultou em fórmulas exatas para atualização da posteriori, uma vez que a integração sobre os choques aleatórios sobre as matrizes de precisão está em forma analítica;


## Caso simples

Considere o seguinte modelo:

\begin{equation}\tag{1}
y_t = \beta y_{t-1} + h_t^{\frac{1}{2}}\varepsilon_t \quad \text{com } \epsilon_t \sim \mathcal{N}(0,1)
\end{equation}

\begin{equation}\tag{2}
h_{t+1} = h_t \frac{\vartheta_t}{\lambda} \quad \text{com } \vartheta_t \sim \mathcal{B}_1(\frac{\nu+1}{2},\frac{1}{2})
\end{equation}

Onde:

* Todos os $\vartheta_t$ 's e $\epsilon_t$ 's são independentes; 
* $t=1, \ldots, T$ é o tempo; 
* $y_t \in \mathbb{R}$ são dados observáveis; 
* $\lambda > 0$ e $\nu > 0$ são parâmetros;
* $\mathcal{B}_1(p,q)$ é a distribuição Beta univariada no intervalo $[0,1]$.

A equação (2) especifica que a precisão não observada $h_t$ do termo $h_t^{\frac{1}{2}}\varepsilon_t$ de (1) é estocástica, de forma que o modelo consegue capturar hererocedasticidade autocorrelacionada (comum em séries temporais financeiras).

A abordagem bayesiana para analisar (1) e (2) irá requerer uma priori $\pi_T(\beta, h_1)$ para $\beta$ e $h_1$, dado $y_0$, com o objetivo de podermos encontrar a distribuição posterior $\pi_T(\beta, h_{T+1})$ dado os dados $y_0, \ldots, y_T$.

Então. fixando $\lambda, \nu > 0$ e escolhendo $\bar{b}_0 \in \mathbb{R}$, $n_0, s_0^2 > 0$ e uma função $g_0(\beta)$ para descrever a densidade a priori:

\begin{equation}\tag{3}
\pi_0(\beta, h_1) \propto g_0(\beta) f_{NG}(\beta, h_1 | \bar{b}_0, \lambda n_0, s_0, \nu)
\end{equation}

Onde $f_{NG}$ denota a densidade da Normal-Gama, dada por:

\begin{equation}\tag{3.1}
f_{NG}(\beta, h_1 | \bar{b}_0, \lambda n_0, s_0, \nu) = \frac{\lambda n_0^{\frac{1}{2}}(\frac{\nu s_0}{2})^{\frac{\nu}{2}}}{(2\pi)^\frac{1}{2}\Gamma(\frac{\nu}{2})} h_1^{\frac{\nu-1}{2}}\exp \left\{-\frac{1}{2}(\beta + \bar{b}_0)^2 \lambda n_0 h_1 - \frac{\nu}{2} s_0 h_1 \right\}
\end{equation}

Para esta distribuição, a precisão $h_1$ segue uma distribuição $\mathcal{G}(s_0, \nu)$ e, condicional a $h$, $\beta$ segue uma distribuição $\mathcal{N}(\bar{b}_0, (\lambda n_0 h_1)^{-1})$.

A forma da priori permite um tratamento mais flexível próximo da raiz unitária através da função $g_0(\beta)$.

Este modelo simples resulta nas seguintes equações:

\begin{equation}\tag{4}
n_t = \lambda n_{t-1} + y_{t-1}^2
\end{equation}

\begin{equation}\tag{5}
\bar{b}_t = \frac{\lambda \bar{b}_{t-1}n_{t-1} + y_t y_{t-1}}{n_t}
\end{equation}

\begin{equation}\tag{6}
s_t = \lambda s_{t-1} + \frac{\lambda}{\nu} e_t^2\left(\frac{1-y_{t-1}^2}{n_t}\right) \quad \text{onde } e_t = y_t - \bar{b}_{t-1}y_{t-1}
\end{equation}

E

\begin{equation}\tag{7}
g_t(\beta) = g_{t-1}(\beta)\left((\beta - \bar{b}_t)^2 n_t + \frac{\nu}{\lambda}s_t \right)^{-\frac{1}{2}}
\end{equation}

Para $t = 1, \ldots, T$. Isto nos dá a seguinte posteriori:

\begin{equation}\tag{7.1}
\pi_T(\beta, h_{T+1}) \propto g_T(\beta) f_{NG}(\beta, h_{T+1}| \bar{\beta}_T, \lambda n_T, s_T, \nu).
\end{equation}

Das equações acima, temos:

* As equações (4) e (5) são as fórmulas recursivas ou as equações do filtro de Kalman para MQG;
* As observações são ponderadas de acordo com o valor de $s_t$ pela equação (7);
* A equação (6) mostra como obter $s_t$ para $h_{t+1}$ (note que em (3) temo $h_1$ e $s_0$) basicamente usando um lag geométrico nos resíduos passados.





# Referências