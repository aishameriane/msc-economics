---
title: "Exemplos Monte Carlo"
author: "Aishameriane Schmidt"
date: "Última atualização: 02 de outubro de 2017"
output: html_document
---

# Exemplos da aula do dia 10/04/17 - Integração por Monte Carlo

## Exemplo 1: Integrando uma função determinística

Suponha que o objetivo é integrar $I = \int_1^2 \exp(\theta)d\theta$ sem usar integração analítica.

Reinterprete $I$ com,o uma esperança em relação a $\theta \sim U(1,2)$ (escolhida de maneira conveniente dentro dos intervalos de integração). Sabemos que a densidade de uma $Uniforme[a,b]$ é $\frac{1}{b-a}$, de forma que $p_U(\theta) = 1/(2-1)$. Obtemos então:

$$I = \int\limits_1^2 \exp\{\theta \} d\theta = (2-1)\int\limits_1^2 \exp\{\theta \}\frac{1}{2-1}d \theta = (2-1) \mathbb{E}_{\mathcal{U}}[\exp\{\theta\}]$$

Para aproximar a integral, simule $S$ observações de $\theta \sim U(1,2)$ e aproxime $\mathbb{E}[\exp(\theta)]$ através da média amostral:

$$\hat{I}_n = \frac{1}{S}\sum\limits_{i=1}^S \exp(\theta_i)$$

Usando $S=10.000$, obtemos $4.7080$ (o valor está diferente das notas de aula possivelmente pela diferença na semente aleatória e no programa), que é uma aproximação razoável para o valor exato `r exp(2)-exp(1)`.

```{r}
# Fixa uma semente aleatória 
#(para poder reproduzir o exemplo depois obtendo os mesmos valores)
set.seed(1234)

# Faz 1000 retiradas de uma Uniforme(1,2) e armazena em um vetor
theta <- runif(1000,min = 1, max = 2)
head(theta)

# Calcula a exponencial do vetor theta
exp_theta <- exp(theta)
head(exp_theta)

# Faz a soma dos valores e divide por S
I_n <- (sum(exp_theta))/length(theta)
I_n
```

## Exemplo 2: FDA da Normal

A F.D.A. Normal padrão, dada por 
$$\Phi(\theta)=\int_{-\infty}^{x}\!\frac{1}{\sqrt{2\pi}}e^{\theta^2/2}\,d\theta$$
não possui fórmula fechada, então pode ser interessante considerar integração MC. Se amostrarmos $\theta^i\sim N(0,1)$, então
$$
\Phi(t)=\int_{-\infty}^{t}\!\frac{1}{\sqrt{2\pi}}e^{\theta^2/2}\,d\theta\approx\widehat{\Phi}_S(t)=\frac{1}{S}\sum_{i=1}^{S}1{\hskip -2.5 pt}\hbox{I}(\theta^{i}\leq t)
$$

Note que $\widehat{\Phi}_S(t)$ é uma variável aleatória Bernoulli, logo sua variância é $\Phi(t)(1-\Phi(t))/S$.
$t$ próximo de 0 implica que a variância de $\widehat{\Phi}_S(t)$ é $1/4S$, logo precisamos de $200.000$ observações, em média, para conseguirmos precisão de 4 dígitos.

```{r}
# Fixa a semente
set.seed(1235)

# Cria um vetor para theta
theta<-rep(0,1)

# Fixa um t
t <- 0

# Cria um vetor para as indicadoras
indicadora <- rep(0,200000)

# Gera um vetor para guardar os thetas
thetas<-rep(0,length(indicadora))

# Gera um valor aleatório da normal padrão e compara com o valor de t
for (i in 1:length(indicadora)){
  theta<-rnorm(1, mean = 0, sd = 1)
  ifelse(theta <= t, indicadora[i] <- 1, indicadora[i]<-0)
  thetas[i]<-theta
}

g_chapeu<-sum(indicadora)/length(indicadora)
sigma_chapeu<-(1/length(indicadora))*sum((thetas-g_chapeu)^2)
desv_pad_num<-sqrt(sigma_chapeu)/(sqrt(length(indicadora)))
```

Comparando o valor tabelado de `r pnorm(t,mean=0,sd=1)` com o valor aproximado de `r sum(indicadora)/length(indicadora)` obtemos uma diferença de `r pnorm(t,mean=0,sd=1) - sum(indicadora)/length(indicadora)` entre eles. O valor de $\hat{\sigma}_g^2$ é de `r round(sigma_chapeu,4)` e portanto o nosso desvio padrão numérico, dado por $\frac{\hat{\sigma}_g}{\sqrt{S}}$, é de `r round(sqrt(sigma_chapeu)/(sqrt(length(indicadora))),4)`. 

Mas para efetivamente saber quão bom é este procedimento (afinal pode ser que tivemos "sorte"), precisamos amostrar várias vezes este valor.

```{r}
# Cria um vetor para theta
theta<-rep(0,1)

# Fixa um t
t <- 0

# Cria um vetor para as indicadoras
indicadora <- rep(0,5000)

# Cria um vetor para as estimativas
agregado <- rep(0,1000)

# Gera 1000 valores aleatórios da normal padrão e compara com o valor de t
# Não é muito eficiente colocar for dentro de for, mas é o que tem pra hoje.
for (j in 1:1000) {
  for (i in 1:length(indicadora)){
    theta<-rnorm(1, mean = 0, sd = 1)
    ifelse(theta <= t, indicadora[i] <- 1, indicadora[i]<-0)
  }
agregado[j]<-sum(indicadora)/length(indicadora)
}
```

A média das nossas estimativas foi de `r round(mean(agregado),4)` e o desvio padrão foi de `r round(sd(agregado),4)`.

Podemos ver na figura abaixo como de fato as diversas realizações de $\hat{g}_S(\theta)$ nos levam a um comportamento similar ao de uma distribuição normal centrada em $0.5$:

```{r, echo=FALSE}
library(latex2exp)
library(ggplot2)

x<-seq(.45,.55,length.out = 5000)
y<-agregado
dados<-data.frame(x,y)

p <- ggplot(dados, aes(x = y)) +
        geom_histogram(color = "black", fill="white", binwidth = .001)+
        ylab(TeX("$\\hat{\\Phi}_N(\\z)$")) +
        xlab("") +
        ggtitle(TeX("Estimated values for $P(Z \\leq 0)$")) +
        scale_colour_brewer(palette="Set1") +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title=element_text(size = 20),
              text=element_text(size = 16),
              axis.text.x=element_text(colour="black", size = 12),
              axis.text.y=element_text(colour="black", size = 12))
p <- p + geom_vline(aes(xintercept=pnorm(0,mean=0,sd=1)),
            color="blue", linetype="dashed", size=1)

#pdf(file="C:\\Users\\Aishameriane\\OneDrive\\Documentos\\Mestrado Economia\\Bayesiana - 2017-01\\Materiais artigo\\Dados\\Imagens artigo\\fig-2_02.pdf")
p
#dev.off()
```

Para $t$ menor que $-4.5$ precisaremos de muito mais observações ainda para conseguir uma estimativa acurada para esta probabilidade.

```{r}
# Seta a semente
set.seed(1234)

# Cria uma variável para theta
theta<-rep(0,1)

# Fixa um t
t <- -4.5

# Cria um vetor para as indicadoras
indicadora <- rep(0,10000)

# Gera um valor aleatório da normal padrão e compara com o valor de t
for (i in 1:length(indicadora)){
  theta<-rnorm(1, mean = 0, sd = 1)
  ifelse(theta <= t, indicadora[i] <- 1, indicadora[i]<-0)
}
```

Observe que em 10.000 realizações nós não encontramos nenhum valor que esteja abaixo de $-4.5$, pois a soma `sum(indicadora)` é igual a `r sum(indicadora)`. Embora a probabilidade seja baixa, ela não é igual a zero: $\mathbb{P}(X \leq -4.5) =$ `r pnorm(t,mean=0,sd=1)` e por isso nosso resultado utilizando o MC tradicional não é confiável.

Podemos fazer o mesmo procedimento que anteriormente para repetir este processo e verificar como ficam nossas estimativas:

```{r}
# Seta a semente
set.seed(1235)

# Uma variável para theta
theta<-rep(0,1)

# Fixa um t
t <- -4.5

# Cria um vetor para as indicadoras
indicadora <- rep(0,10000)

# Cria um vetor para ir salvando as estimativas
agregado<-rep(0,1000)

# Gera um valor aleatório da normal padrão e compara com o valor de t
for (j in 1:length(agregado)){
  for (i in 1:length(indicadora)){
    theta<-rnorm(1, mean = 0, sd = 1)
    ifelse(theta <= t, indicadora[i] <- 1, indicadora[i]<-0)
  }
agregado[j]<-sum(indicadora)/length(indicadora)
}
```
A média das nossas estimativas foi de `r round(mean(agregado),4)` e o desvio padrão foi de `r round(sd(agregado),4)`, enquanto que o valor esperado seria de  $\mathbb{P}(X \leq -4.5) =$ `r pnorm(t,mean=0,sd=1)`.

Podemos novamente plotar o gráfico:

```{r, echo=FALSE}
library(latex2exp)
library(ggplot2)

x<-seq(.45,.55,length.out = 5000)
y<-agregado
dados<-data.frame(x,y)

p <- ggplot(dados, aes(x = y)) +
        geom_histogram(color = "black", fill="white", binwidth = .000001)+
        ylab(TeX("$\\hat{\\Phi}_N(z)$")) +
        xlab("") +
        ggtitle(TeX("Estimated values for $P(Z \\leq -4.5)$")) +
        scale_colour_brewer(palette="Set1") +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title=element_text(size = 20),
              text=element_text(size = 16),
              axis.text.x=element_text(colour="black", size = 12),
              axis.text.y=element_text(colour="black", size = 12))
p <- p + geom_vline(aes(xintercept=pnorm(-4.5,mean=0,sd=1)),
            color="blue", linetype="dashed", size=1)

#pdf(file="C:\\Users\\Aishameriane\\OneDrive\\Documentos\\Mestrado Economia\\Bayesiana - 2017-01\\Materiais artigo\\Dados\\Imagens artigo\\fig-2_03.pdf")
p
#dev.off()
```

Pela figura observamos que de fato as estimativas ficaram muito concentradas em zero.

Mas então como calcular probabilidades de eventos raros utilizando métodos de Monte Carlo? Utilizando amostragem por eficiência.

Calcular probabilidade de eventos raros como $\Phi(-4.5)$ usando este método MC simples é difícil, pois muito raramente iremos amostrar $\theta^i$ tal que $1{\hskip -2.5 pt}\hbox{I}(\theta^{i}\leq -4.5)=1$, logo $\widehat{\Phi}_S(-4.5)=0$ mesmo para um valor alto de $S$. Mas usando a regra de mudança de variáveis, podemos usar $v=\frac{1}{x}$:
$$
\int_{-\infty}^{-4.5}\!\frac{1}{\sqrt{2\pi}}e^{\theta^2/2}\,d\theta=\int^{0}_{\frac{-1}{4.5}}\!\frac{\phi(1/v)}{v^2}dv=\frac{1}{4.5}\int^{0}_{\frac{-1}{4.5}}\!\frac{\phi(1/v)}{v^2}p_U(v)dv
$$

Podemos amostrar $v_i\sim U(-1/4.5,0)$, então:
$$
\int_{-\infty}^{-4.5}\!\frac{1}{\sqrt{2\pi}}e^{\theta^2/2}\,d\theta\approx\widehat{\Phi}^U_S(-4.5)=\frac{1}{S}\sum_{i=1}^S\frac{\phi(1/v^i)}{4.5v^{i^2}}
$$

Note que a F.D.P. de $v$ $p_U(v)=4.5$ é usada no denominador para compensar o fato de que não amostramos da distribuição original, mas sim de uma distribuição alternativa.

```{r}
# Define um tamanho de S e faz S retiradas de uma uniforme(-1/4.5, 0)
S<-20
vetor_v <- runif(S, min =(1/-4.5) , max = 0)

# Calcula a aproximação
numerador<- dnorm(1/vetor_v, mean=0, sd=1)
denominador<- 4.5*vetor_v^2
aproximacao<- (1/length(vetor_v))*sum(numerador/denominador)

# Calcula o desvio padrão
sigma_chapeu<-(1/length(vetor_v))*sum((vetor_v-aproximacao)^2)
desv_pad_num<-sqrt(sigma_chapeu)/(sqrt(length(vetor_v)))
```

Nosso valor estimado é de `r round(aproximacao, 4)`, enquanto o valor esperado era de $\mathbb{P}(X \leq -4.5) =$ `r pnorm(t,mean=0,sd=1)`. Podemos calcular também o desvio padrão numérico: $\frac{\hat{\sigma}_g}{\sqrt{S}}=$ `r round(desv_pad_num,4)`.

Novamente, vamos gerar várias estimativas para poder comparar com o método anterior:
```{r}
# Define um tamanho de S e faz S retiradas de uma uniforme(-1/4.5, 0)
S<-10000

# Cria os vetores que vão ser usados no laço for
vetor_v<-seq(0,S)
numerador<-seq(0,S)
denominador<-seq(0,S)
estimativas<-seq(1,500)

for (j in 1:length(estimativas)){
    vetor_v <- runif(S, min =(1/-4.5) , max = 0)
    numerador<- dnorm(1/vetor_v, mean=0, sd=1)
    denominador<- 4.5*vetor_v^2
    aproximacao<- (1/length(vetor_v))*sum(numerador/denominador)
  estimativas[j]<-aproximacao
}

mean(estimativas)
```


```{r, echo=FALSE}
library(latex2exp)
library(ggplot2)

x<-seq(.45,.55,length.out = 5000)
y<-estimativas
dados<-data.frame(x,y)

p <- ggplot(dados, aes(x = y)) +
        geom_histogram(color = "black", fill="white", binwidth = .00000001)+
        ylab(TeX("$\\hat{\\Phi}_N(z)$")) +
        xlab("") +
        ggtitle(TeX("Estimating $P(Z \\leq)$ using importance sampling")) +
        scale_colour_brewer(palette="Set1") +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title=element_text(size = 12),
              text=element_text(size = 12),
              axis.text.x=element_text(colour="black", size = 12),
              axis.text.y=element_text(colour="black", size = 12))

p <- p + geom_vline(aes(xintercept=pnorm(-4.5,mean=0,sd=1)),
            color="red", linetype="dashed", size=1)

#pdf(file="C:\\Users\\Aishameriane\\OneDrive\\Documentos\\Mestrado Economia\\Bayesiana - 2017-01\\Materiais artigo\\Dados\\Imagens artigo\\fig-2_04.pdf")
p
#dev.off()
```
