---
title: "Amostrador de Gibbs"
author: "Aishameriane Schmidt"
date: "Última atualização: 11 abril 2018"
header-includes:
   - \usepackage{bigints}
   - \usepackage[brazil]{babel}
   - \usepackage{graphicx}
   - \usepackage{amsmath}
   - \usepackage{amsfonts}
   -  \usepackage{calrsfs}
   - \usepackage{mathrsfs}
   - \usepackage{upgreek}
output: html_document
bibliography: references.bib
---

\begin{align*}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}\\
\def\I{{\mathbb I}}\\
\def\P{{\mathbb P}}\\
\def\E{{\mathbb E}}\\
\def\V{{\mathbb V}}\\
\def\R{{\mathbb R}}\\
\def\N{{\mathbb N}}\\
\def\Q{{\mathbb Q}}\\
\newcommand{\Or}{{\mathrm O}}\\
\newcommand{\A}{{\mathcal A}}\\
\newcommand{\C}{{\mathbb C}}\\
\newcommand{\K}{{\mathbb K}}\\
\newcommand{\Z}{{\mathbb Z}}
\end{align*}


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { 
      equationNumbers: {
 
            autoNumber: "all",
            formatNumber: function (n) {return '9.'+n}
      } 
  }
});
</script>

- Seção 6.2.2 de [@bchoice]
- Seção 3.3 de [@casella_MC]
- Capítulo 6 de [@casella_MCR]
- Capítulo 3 de [@BLR]
- Capítulo 7 de [@greenberg2008]
- [@chib2001]
- [@chib2013]
- [@geweke1996]
- [@suess_trumbo2010]
- [@casella_george1992]

# Carregando os pacotes

```{r, message = FALSE, warning = FALSE}
chooseCRANmirror(graphics = FALSE, ind = 10)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, gridExtra, latex2exp, RColorBrewer, ggfortify, car, rgl, rglwidget, psych, rmutil, VGAM, invgamma)
``` 

# Dúvidas

Dúvidas em <span style="color:blue">**azul**</span> eu acho que já entendi, mas deixei aqui a resposta para que a Aisha do futuro possa consultar também. Dúvidas em <span style="color:red">**vermelho**</span> ainda precisam de resposta.

1.  <span style="color:red">**Dúvida 1:**</span> Qual a melhor tradução para _full conditional_? Eu coloquei como ''densidade condicional a todos os outros parâmetros''.

<span style="color:green">**Resposta**</span>:

2.  <span style="color:red">**Dúvida 2:**</span> O [@casella_MCR] fala que _"The appeal of those specific algorithms (Gibbs sampler) is that first they gather most of their **calibration** from the target density"_. Eu não entendi essa parte. Quer dizer que outros algoritmos, como o MH, não fazem "calibração" a partir da densidade alvo? Isso é porque usamos uma candidata que não necessariamente tem a ver com a densidade alvo e no Gibbs por usarmos as condicionais a gente necessariamente cai na densidade alvo? 

<span style="color:green">**Resposta**</span>: 

3.  <span style="color:red">**Dúvida 3:**</span> No segundo exemplo bivariadoo (da beta-binomial) nós construímos o Gibbs usando $f(X|\theta)$ e $f(\theta)$ para gerar as sequências $\{X,\theta\}$. Quer dizer então que não precisa ser sempre de uma condicional? Achei que sempre seria algo na linha do algoritmo 2. Esse exemplos está no [@casella_MCR] e no [@casella_george1992]. É por quê nesse exemplo específico ele quer apenas $f(x)$ e por isso está gerando amostras de $\theta$ apenas para conseguir plugar na condicional e não necessariamente quer os $\theta$?

<span style="color:green">**Resposta**</span>:

4.  <span style="color:blue">**Dúvida 4:**</span> Como é feito o histograma da Beta-Binomial da figura 1 de [@casella_george1992]? Porque nós temos um vetor bivariado de com $\{x,y\}$ (a distribuição conjunta deles que é beta binomial.)

<span style="color:green">**Resposta**</span>: Na segunda coluna da página 2, abaixo da equação (2.7) diz que _"Figure 1 displays histograms of two samples $x_1, \ldots, x_m$ of size $m=500$ from the beta-binomial distribution with $n=16$, $\alpha=2$ and $\beta=4$."_. Tá, isso faz sentido porque no início do exemplo ele diz que está justamente interessado em $f(x)$, a marginal de $X$.

5.  <span style="color:red">**Dúvida 5:**</span> Acho que tem um typo na equação 7.3 do [@casella_MCR], mas não achei errata do livro. No último termo, que é o núcleo da inversa gamma, acho que o $b$ não fica no denominador com a variável aleatória e esse expoente é negativo (ver a definição que ele dá no final da página 202).

<span style="color:green">**Resposta**</span>: 

6. <span style="color:blue">**Dúvida 6:**</span> No [casella_MCR] na página 203, no exemplo da Normal ele diz que não é um modelo conjugado e por isso não conseguimos uma densidade tabelada ao integrar $\theta$ e $\sigma^2$.

<span style="color:green">**Resposta**</span>: Se olhar bem, os parâmetros a variância de $\theta$ não é $\sigma^2$ e por isso não estamos no modelo conjugado. 

# Introdução

A origem do amostrador de Gibbs é o trabalho de Geman e Geman (1984), cuja aplicação era em [campos aleatórios de Gibbs](http://www.nlpr.ia.ac.cn/users/szli/MRF_Book/Chapter_1/node12.html) (_Gibbs random fields_). Pode-se mostrar que o amostrador de Gibbs é um caso particular do algoritmo de Metropolis-Hastings, onde os parâmetros são agrupados em blocos que, por sua vez, são amostrados de forma condicional uns aos outros. Por exemplo, supondo que temos interesse no parâmetro $\theta$ e que ele pode ser escrito como uma partição $\theta = (\theta_1, \theta_2, \ldots, \theta_p)$ (onde $\theta_i, \ i \in \{1, \ldots, p\}$ pode ser escalar ou vetorial), então usaremos as distribuições condicionais de $\theta_i| \theta_1, \ldots, \theta_{i-1}, \theta_{i+1}, \ldots, \theta_p$, $\forall\ i$ de maneira a obter amostras de todos os $\theta_i$ [@chib2001]. Esse procedimento equivale a escolher como densidade candidata as densidades condicionais a todos os outros parâmetros (também chamada de _full conditional_ - <span style="color:red">**Dúvida**: Qual a melhor tradução de _full conditional_? </span>). Como resultado, a probabilidade de aceitação, a cada passo, é sempre igual a $1$ [@chib2013]. No entanto, como não estou falando de Metropolis-Hastings antes, vou fazer a abordagem partindo diretamente do Gibbs.

Assim como os demais métodos de MCMC, o amostrador de Gibbs é uma técnica de gerar variáveis aleatórias de uma distribuição $f$ de maneira indireta, sem necessariamente amostrar de $f$. [@casella_MCR] cita duas principais vantagens do amostrador de Gibbs: a primeira é que o método usa praticamente apenas a densidade alvo (<span style="color:red">**ver a dúvida no início do documento sobre isso**</span>) e a segunda é que nos permite quebrar um problema complexo em diversos problemas de dimensão menor. No exemplo do parágrafo anterior, se temos $m$ parâmetros, poderíamos "dividir" o problema em amostrar condicionalmente cada um dos $m$ parâmetros, formando uma cadeia de Markov cuja densidade estacionária fosse a posteriori de $\theta$. [@casella_george1992] chamam atenção para o fato de que, embora seja amplamente aplicado em problemas bayesianos, é possível utilizar o amostrador de Gibbs em problemas frequentistas também.

# Noções básicas

**Definição 1** Amostrador de Gibbs (adaptado de [@casella_MC])

Suponha que para algum $p>1$ a variável aleatória $\theta \in \Theta$ pode ser escrita como $\theta = (\theta_1, \theta_2, \ldots, \theta_p)$ (onde $\theta_i, \ i \in \{1, \ldots, p\}$ pode ser escalar ou vetorial). Suponha ainda que pode-se simular das densidades univariadas condicionais $f_1, \ldots, f_p$, isto é, é possível amostrar
$$\theta_i|\underline{\theta}_1, \ldots, \underline{\theta}_{i-1}, \underline{\theta}_{i+1}, \ldots, \underline{\theta}_p  \sim f_i(\underline{\theta}_{i}|\underline{\theta}_1, \ldots, \underline{\theta}_{i-1}, \underline{\theta}_{i+1}, \ldots, \underline{\theta}_p)$$
com $i=1, \ldots, p$. O _algoritmo de amostragem de Gibbs_ (ou _amostrador de Gibbs_) correspondente é dado pela transição de $\theta^{(t)}$ para $\theta^{(t+1)}$:

**Algoritmo 1 - Amostrador de Gibbs **

* Dado $\theta^{(t)} = (\theta_1^{(t)}, \ldots, \theta_p^{(t)})$, gere
    1. $\theta_1^{(t+1)} \sim f_1(\theta_1|\theta_2^{(t)}, \ldots, \theta_p^{(t)})$
    2. $\theta_2^{(t+1)} \sim f_2(\theta_2|\theta_1^{(t+1)}, \theta_3^{(t)}, \ldots, \theta_p^{(t)})$
    
    $\hspace{1cm} \vdots$
    
    p. $\theta_p^{(t+1)} \sim f_p(\theta_p|\theta_1^{(t+1)}, \theta_2^{(t+1)}, \ldots, \theta_{p-1}^{(t+1)})$

Chamamos as densidades $f_1, \ldots, f_p$ de _full conditionals_. Note que o algoritmo 1 implica que apenas essas densidades são usadas para simulação e, como dito anteriormente, podemos reduzir um problema de dimensão $p$ em $p$ problemas univariados [@casella_MC].

# Exemplos

## Caso bivariado

(Retirado de [@casella_MCR])
Considere $\theta=(\theta_1, \theta_2)$ com distribuição conjunta $f(\theta_1, \theta_2)$ e condicionais denotadas por $f_{\theta_1|\theta_2}$ e $f_{\theta_2|\theta_1}$. Neste caso, o amostrador de Gibbs correspondente é também chamado de _amostrador de Gibss em dois estágios_ (_two stage Gibbs sampler_) e consiste em gerar uma cadeia de Markov $\{\theta_1, \theta_2\}$ da seguinte forma:

**Algoritmo 2 - Amostrador de Gibbs em dois estágios** 

* Dado $\theta_1^{(0)} = \underline{\theta}_1^{(0)}$, gere
    1. $\theta_2^{(t)} \sim f_{\theta_2|\theta_1}(\cdot | \theta_1^{(t-1)})$
    2. $\theta_1^{(t)} \sim f_{\theta_1|\theta_2}(\cdot | \theta_2^{(t)})$
    
### Exemplo 1: A normal bivariada (adaptado de [@casella_MCR])

Considere o modelo dado por:

\begin{align*}
(X,Y) \sim \mathcal{N}_2\left(0, \begin{pmatrix}1 & \rho \\ \rho & 1 \end{pmatrix} \right)
\end{align*}

Primeiro vamos calcular as marginais. Uma forma de fazer é na "força bruta", como está [aqui](http://fourier.eng.hmc.edu/e161/lectures/gaussianprocess/node7.html). A outra forma é acreditar no teorema que diz que as condicionais na distribuição normal multivariada são também normais e aí calcular a média e a variância condicional (peguei [daqui](http://athenasc.com/Bivariate-Normal.pdf) e [daqui](https://stats.stackexchange.com/questions/30588/deriving-the-conditional-distributions-of-a-multivariate-normal-distribution)).

Primeiro, vamos definir uma v.a. auxiliares (vou fazer para o caso genérico onde $\theta_1 \sim \mathcal{N}(\mu_1, \sigma^2_1)$ e $\theta_2 \sim \mathcal{N}(\mu_2, \sigma^2_2)$:

\begin{equation}\tag{01}
Z = \theta_1 + A\theta_2
\end{equation}
em que $A = -\frac{\rho}{\sigma_2^2}$, com $\rho$ sendo a correlação entre $\theta_1$ e $\theta_2$. Note que $Z$ é uma combinação linear de v.a. com distribuição normal e portanto tem também distribuição normal. Vamos calcular a covariância entre $Z$ e $\theta_2$:

\begin{align*}
Cov[Z, \theta_2] &= Cov[\theta_1 + A\theta_2, \theta _2]\\
&= Cov[\theta_1, \theta_2] + Cov[A\theta_2,\theta_2]\\
&= \rho + A Var[\theta_2] \\
&= \rho + A \sigma_2^2 \\
&= \rho + -\frac{\rho}{\sigma_2}\sigma_2^2 = 0
\end{align*}
E com isso descobrimos que $Z$ e $\theta_2$ são independentes (pois na distribuição normal multivariada [ausência de correlação necessariamente implica independência](https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Correlations_and_independence)).

A esperança de $Z$ é dada por $\E[Z]= \E[\theta_1 + A\theta_2] = \mu_1 + A\mu_2$. Logo, a esperança condicional de $\theta_1$ dado $\theta_2$ será:

\begin{align*}
\E[\theta_1|\theta_2] &= \E[Z - A\theta_2|\theta_2]\\
&= \E[Z|\theta_2] - \E[A\theta_2|\theta_2]\\
&= \E[Z] - A\theta_2\\
&= \mu_1 + A\mu_2- A\theta_2\\
&= \mu_1 + A(\mu_2 - \theta_2)\\
&= \mu_1 -\frac{\rho}{\sigma_2^2}(\mu_2 - \theta_2)
\end{align*}

Se $\mu_1 = \mu_2 = 0$ e $\sigma_2 = 1$, então $\E[\theta_1|\theta_2] = \rho\theta_2$. Para a variância, teremos:

\begin{align*}
Var[\theta_1|\theta_2] &= Var[Z - A\theta_2|\theta_2]\\
&= Var[Z|\theta_2] + Var[-\frac{\rho}{\sigma_2^2}\theta_2|\theta_2] -2ACov[Z, -\theta_2]\\
&= Var[Z|\theta_2]\\
&= Var[Z]\\
&= Var[\theta_1 + A\theta_2]\\
&= Var[\theta_1] + Var[A\theta_2] + 2ACov(\theta_1, \theta_2)\\
&= \sigma_1^2 +\frac{\rho^2}{(\sigma_2^2)^2}\sigma_2^2 -2\frac{\rho}{\sigma_2^2}\rho\\
&= \sigma_1^2 +\frac{\rho^2}{\sigma_2^2} + 2\frac{\rho^2}{\sigma_2^2}\\
&= \sigma_1^2 -\frac{\rho^2}{\sigma_2^2}
\end{align*}
Obs: note que [$Var[X|X]= 0$](https://math.stackexchange.com/questions/1738414/what-is-the-variance-of-a-variable-given-itself). Da mesma forma, se $\sigma_1 = \sigma_2 = 1$, então $Var[\theta_1|\theta_2] = 1 - \rho^2$.

Assim, nosso amostrador de Gibbs será dado por:

**Algoritmo 3 - Amostrador de Gibbs em dois estágios para a normal bivariada** 

* Dado $\theta_1^{(0)} = \underline{\theta}_1^{(0)}$, gere
    1. $\theta_2^{(t+1)}|\theta_1^{(t)} \sim \mathcal{N}(\rho\cdot\theta_1^{(t)}, 1 - \rho^2)$
    2. $\theta_1^{(t+1)}|\theta_2^{(t+1)} \sim \mathcal{N}(\rho\cdot\theta_2^{(t+1)}, 1 - \rho^2)$

```{r}    
set.seed(6969)
theta1_init <- runif(1, min = -4, max = 4)

theta1 <- vector()
theta2 <- vector()


rho    <- 0.5
tesao  <- 100000

for (i in 1:tesao){
  if(i == 1){
    theta2[i] <- rnorm(n = 1, mean = rho*theta1_init, sd = 1-rho^2)
  } else {
    theta2[i] <- rnorm(n = 1, mean = rho*theta1[i-1], sd = 1-rho^2)
  }
  theta1[i] <- rnorm(n = 1, mean = rho*theta2[i], sd = 1-rho^2)
}

bvn <- cbind(theta1, theta2)
```

```{r, webGL = TRUE, echo = FALSE, eval = FALSE}
# Agora vamos fazer um gráfico bonitão
# Ele não carrega no github :|

hx <- hist(bvn[,2], plot=FALSE)
hxs <- hx$density / sum(hx$density)
hy <- hist(bvn[,1], plot=FALSE)
hys <- hy$density / sum(hy$density)

## [xy]max: so that there's no overlap in the adjoining corner
xmax <- tail(hx$breaks, n=1) + diff(tail(hx$breaks, n=2))
ymax <- tail(hy$breaks, n=1) + diff(tail(hy$breaks, n=2))
zmax <- max(hxs, hys)

## the base scatterplot
plot3d(bvn[,2], bvn[,1], 0, zlim=c(0, zmax), pch='.', xlab='X', ylab='Y', zlab='', axes=FALSE)
par3d(scale=c(1,1,3))

## manually create each histogram
for (ii in seq_along(hx$counts)) {
    quads3d(hx$breaks[ii]*c(.9,.9,.1,.1) + hx$breaks[ii+1]*c(.1,.1,.9,.9),
            rep(ymax, 4),
            hxs[ii]*c(0,1,1,0), color='gray80')
}
for (ii in seq_along(hy$counts)) {
    quads3d(rep(xmax, 4),
            hy$breaks[ii]*c(.9,.9,.1,.1) + hy$breaks[ii+1]*c(.1,.1,.9,.9),
            hys[ii]*c(0,1,1,0), color='gray80')
}

# I use these to ensure the lines are plotted "in front of" the
## respective dot/hist
bb <- par3d('bbox')
inset <- 0.02 # percent off of the floor/wall for lines
x1 <- bb[1] + (1-inset)*diff(bb[1:2])
y1 <- bb[3] + (1-inset)*diff(bb[3:4])
z1 <- bb[5] + inset*diff(bb[5:6])

## even with draw=FALSE, dataEllipse still pops up a dev, so I create
## a dummy dev and destroy it ... better way to do this?
#dev.new()
de <- dataEllipse(bvn[,1], bvn[,2], draw=FALSE, levels=0.95)
#dev.off()

## the ellipse
lines3d(de[,2], de[,1], z1, color='green', lwd=3)

## the two density curves, probability-style
denx <- density(bvn[,2])
lines3d(denx$x, rep(y1, length(denx$x)), denx$y / sum(hx$density), col='red', lwd=3)
deny <- density(bvn[,1])
lines3d(rep(x1, length(deny$x)), deny$x, deny$y / sum(hy$density), col='blue', lwd=3)

grid3d(c('x+', 'y+', 'z-'), n=10)
#box3d()
axes3d(edges=c('x-', 'y-', 'z+'))
outset <- 1.2 # place text outside of bbox *this* percentage
mtext3d('P(X)', edge='x+', pos=c(0, ymax, outset * zmax))
mtext3d('P(Y)', edge='y+', pos=c(xmax, 0, outset * zmax))
rglwidget()
```

```{r}
# É tipo um gráfico reserva, já que o outro está dando ruim pra visualizar na Web
scatter.hist(x=bvn[,1], y=bvn[,2], density=TRUE, ellipse=TRUE)
```

Ambos gráficos peguei [nesta thread](https://stackoverflow.com/questions/19949435/3d-plot-of-bivariate-distribution-using-r-or-matlab). Já para fazer o gráfico 3D funcionar no html, vi [aqui](http://www.stats.uwo.ca/faculty/murdoch/talks/2015-12-02/rgl_on_the_web.html).

### Exemplo 2: Modelo hierárquico simples (adaptado de [@casella_MCR] e [@casella_george1992])

Considere a distribuição dada por
$$f(x, \theta) = {n\choose x} \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\theta^{x+a+1}(1-\theta)^{n-x+b-1}, \qquad \text{com} \quad 0 \leq \theta \leq 1 \quad \text{e} \quad x = 1, 2, \ldots, n.$$

Nosso interesse é amostrar da marginal de $X$, mas vamos supor que não temos como fazer isso diretamente.

Vamos calcular a densidade marginal de $\theta$:

\begin{align*}
f(\theta) &= \sum_{i=1}^n f(x_i, \theta) = \sum_{i=1}^n {n\choose x_i} \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\theta^{x_i+a+1}(1-\theta)^{n-x_i+b-1}\\
&= \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{a-1}(1-\theta)^{b-1} \sum_{i=1}^n {n\choose x_i}\theta^{x_i}(1-\theta)^{n-x_i}\\
&= \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{a-1}(1-\theta)^{b-1} \Rightarrow \theta \sim \mathcal{B}(\alpha,\beta)
\end{align*}
Note que para sumir com o somatório consideramos que era a f.m.p. de uma v.a. Binomial.

Agora, para calcular a condicional de $x|\theta$, usamos o teorema de Bayes:

\begin{align*}
f(x|\theta) &=\frac{f(x,\theta)}{f(\theta)} = \frac{{n\choose x} \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\theta^{x+a+1}(1-\theta)^{n-x+b-1}}{\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{a-1}(1-\theta)^{b-1}}\\
&= {n\choose x} \theta^{x}(1-\theta)^{n-x}
\end{align*}

Que é a densidade de uma v.a. Binomial com parâmetros $n$ e $\theta$. Assim, $X|\theta \sim \text{Binomial}(n,\theta)$ e $\theta \sim \mathcal{B}(a,b) \Rightarrow \theta|x \sim \mathcal{B}(x + a, n-x+b)$ e podemos implementar um amostrador de Gibbs da seguinte forma (adaptei o código do [@casella_MCR]).

**Obs:** A densidade marginal de X é uma Beta-Binomial(n,a,b), mas estamos fingindo que não sabemos disso.

```{r}
Nsim  <- 5000
n     <- 15
a     <- 3
b     <- 7
x     <-vector()
theta <- vector()

# Valores iniciais
theta[1] <- rbeta(1,a,b)
x[1]     <- rbinom(1,n,theta[1])

for (i in 2:Nsim){
  x[i] <- rbinom(1, n, theta[i-1])
  theta[i] <- rbeta(1, a+x[i], n-x[i]+b)
}

cores <- brewer.pal(6, "Dark2")
cores2 <- brewer.pal(10, "Paired")
cadeiadf <- data.frame(1:Nsim, x, theta)

p1 <- ggplot(cadeiadf, aes(x=cadeiadf$x)) + 
    geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
      binwidth=.5, fill = cores[3], colour = cores[3], alpha=0.5)+
    # stat_function(
    #   fun = function(x, size, shape1, shape2, n, bw){
    #     dbetabinom.ab(x =x, size = n, shape1 = a, shape2 = b)
    # },
    # args = c(size = n, shape1 = a, shape2 = b, n = length(cadeiadf$x), bw = .5), colour = cores2[10], size = 1, geom = "line")+ #dont know what's wrong
  #geom_density(colour = cores2[10])+
  labs(title= TeX('$X \\sim$ Beta-Binomial ($n$,$a$, $b$) - Simulado'), y = "", x= TeX('$X$'), color = "Variável") +
    theme(plot.title=element_text(size = 12),
              text=element_text(size = 12),
              axis.text.x=element_text(colour="black", size = 10),
              axis.text.y=element_text(colour="black", size = 10),
              panel.background = element_blank(),
              panel.grid.major = element_line(colour = "gray"),
              panel.grid.minor = element_line(),
              panel.border = element_rect(colour = "black", fill = NA))
p1 <- p1 + geom_vline(aes(xintercept=mean(cadeiadf$x)),
            color="purple", linetype="dashed", size=1) + annotate("text", x = 10, y = 0.15, label = paste0("Média dos\n valores simulados\n", round(mean(cadeiadf$x),4)), size = 2.5)

p2<- ggplot(cadeiadf, aes(x=theta)) + 
    geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
      binwidth=.05, fill = cores[1], colour = cores[1], alpha=0.5)+
    # stat_function(
    #   fun = function(x, shape1, shape2, n, bw){
    #     dbeta(x = theta, shape1 = a, shape2 = b)
    # },
    # args = c(shape1 = a, shape2 = b, n = length(theta), bw = .5), colour = cores2[10], size = 1)+ #dont know what's wrong
  #geom_density(colour = cores2[4])+
  labs(title= TeX('$\\theta \\sim B(a,b)$'), y = "", x= TeX('$\\theta$'), color = "Variável") +
    theme(plot.title=element_text(size = 12),
              text=element_text(size = 12),
              axis.text.x=element_text(colour="black", size = 10),
              axis.text.y=element_text(colour="black", size = 10),
              panel.background = element_blank(),
              panel.grid.major = element_line(colour = "gray"),
              panel.grid.minor = element_line(),
              panel.border = element_rect(colour = "black", fill = NA))
p2 <- p2 + geom_vline(aes(xintercept=mean(theta)),
            color="darkgreen", linetype="dashed", size=1) + annotate("text", x = 0.65, y = 1.5, label = paste0("Média dos\n valores simulados\n", round(mean(cadeiadf$theta),4)), size = 2.5)

df2 <- data.frame(seq(1,n), dbetabinom.ab(seq(1,n),n,a,b))
names(df2) <- c("X", "densidade")

p3 <- ggplot(df2, aes(x=X, y=densidade)) + 
    geom_bar(stat="identity",
      width=.5, fill = cores[4], colour = cores[4], alpha=0.5)+
  labs(title= TeX('$X \\sim$ Beta-Binomial ($n$,$a$, $b$) - Teórico'), y = "", x= TeX('$X$'), color = "Variável") +
    theme(plot.title=element_text(size = 12),
              text=element_text(size = 12),
              axis.text.x=element_text(colour="black", size = 10),
              axis.text.y=element_text(colour="black", size = 10),
              panel.background = element_blank(),
              panel.grid.major = element_line(colour = "gray"),
              panel.grid.minor = element_line(),
              panel.border = element_rect(colour = "black", fill = NA))
p3 <- p3 + geom_vline(aes(xintercept=n*a/(a+b)),
            color="pink", linetype="dashed", size=1) + annotate("text", x = 8, y = 0.12, label = paste0("Média da\n distribuição teórica\n", round(n*a/(a+b),4)), size = 2.5)

grid.arrange(p1, p3, ncol = 2, nrow = 1)

#Plot as distribuições dos x e dos thetas
grid.arrange(p1, p2, ncol = 2, nrow = 1)
```

Obs: A altura dos histogramas dos valores simulados e teóricos está diferente pois para os valores simulados foi utilizada uma função que estima a densidade a partir do histograma. Se você plotar um histograma usando o plot simples do R, vai ver que eles dão iguais.

Obs2: Usei uma função pronta para calcular a beta-binomial (função `dbetabinom.ab` do pacote `VGAM`), mas caso você não consiga usar ele, pode implementar diretamente a densidade a partir da equação:

$$f(X|n, a, b) = \frac{\Gamma(n+1)}{\Gamma(x+1)\Gamma(n-x+1)}\cdot\frac{\Gamma(x+a)\Gamma(n-x+b)}{\Gamma(n+a+b)}\cdot\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} $$

<span style="color:red">**Para a Aisha do futuro:** Tem problema nas funções `stat_function`, na primeira ele plota uma flat line e na segunda ele reclama que as coisas não tem mesmo número de linhas. Tem que dar uma pensada.</span>

### Exemplo 3: A distribuição normal (adaptado de [@casella_MCR])

Considere a distribuição posterior de $(\theta, \sigma^2)$ associada com o modelo conjunto dado por
\begin{align*}
X_i \sim \mathcal{N}(\theta, \sigma^2), \quad i = 1,\ldots, n\\
\theta \sim \mathcal{N}(\theta_0, \tau^2) \quad \sigma^2 \sim \mathcal{IG}(a,b)
\end{align*}
em que $\mathcal{IG}$ denota a distribuição inversa-gama (definida no teorema 1) e $\theta_0$, $\tau^2$, $a$, $b$ são hiperparâmetros.

----
**Teorema 1: Distribuição inversa gama**

Seja $X$ uma v.a. que segue uma distribuição Gama($\alpha$, $\beta$). Então, $\frac{1}{X}$ segue uma distribuição inversa-gama de parâmetros $\alpha$ e $1/ \beta$.

(tem outras versões que vão alterar o parâmetro $\beta$, essa parametrização que eu uso fica desse jeito. Na wikipedia, fica inversa-gama($\alpha$, $\beta$).)

_Demonstração_:

A densidade da Inversa-Gama($\alpha$, $\beta$) é dada por:
$$f(z) = \frac{\beta^\alpha}{\Gamma(\alpha)} z^{-\alpha-1}\exp^{\frac{-\beta}{z}}$$
Enquanto que a densidade da Gama($\alpha$, $\beta$) é dada por (obs: existe mais de uma forma de definir a densidade Gama):
$$f(x) = \frac{1}{\beta^\alpha\Gamma(\alpha)} x^{\alpha-1}\exp^{-\frac{x}{\beta}}$$
Agora, defina $Y=g(X)=\frac{1}{X}$. Como uma função de v.a. também é uma v.a., pode-se tentar descobrir qual é a densidade de $Y$. Isso pode ser feito com f.g.m. (primeiro teríamos que derivar a f.g.m da inversa gama, depois a da gama e finalmente calcular a de 1/X para X gama e comparar com a da inversa gama). Uma outra forma é usar o [teorema da transformação](http://math.arizona.edu/~jwatkins/f-transform.pdf). 

\begin{align*}
f_Y(y) = f_X(1/y) \lvert \frac{d}{dy}y^{-1} \rvert \\
&= \frac{1}{\Gamma(\alpha) \beta^\alpha}\cdot y^{-\alpha+1} \exp \left\{- \frac{1}{\beta \cdot y} \right\} \cdot y^{-2}\\
&= \frac{\frac{1}{\beta}^\alpha}{\Gamma(\alpha)} \cdot y^{-\alpha - 1} \exp \left\{- \frac{\frac{1}{\beta}}{y} \right\}.
\end{align*}
----

Escrevendo $\mathbf{x}=(x_1, \ldots, x_n)$ a distribuição à posteriori de $(\theta, \sigma^2)$ é dada por:

\begin{align*}
f(\theta, \sigma^2|\mathbf{x}) &\propto \left[\frac{1}{(\sigma^2)^{n/2}}\exp\left\{-\frac{-\sum_i (x_i - \theta)^2}{2\sigma^2} \right\} \right]\\
&\times \left[\frac{1}{\tau}\exp \left\{-\frac{-(\theta-\theta_0)^2}{2\tau^2} \right\} \right]\cdot \left[\frac{1}{(\sigma^2)^{a+1}}\exp\left\{\frac{1}{b\sigma^2} \right\} \right]
\end{align*}
Note que essa não é uma distribuição conhecida (tabelada) e por isso não conseguimos amostrar dela. Porém, nós conseguimos calcular as condicionais, que serão dadas por:

\begin{align}
\pi(\theta|\mathbf{x}, \sigma^2) &\propto \exp\left\{\frac{1}{2\sigma^2}-\sum_i (x_i - \theta)^2 \right\} \exp \left\{-\frac{-(\theta-\theta_0)^2}{2\tau^2} \right\} \tag{7.4}\\
\pi(\sigma^2|\mathbb{x}, \theta) &\propto \left(\frac{1}{\sigma^2} \right)^{\frac{n+2a+3}{2}}\exp \left\{-\frac{1}{2\sigma^2} \right\}
\end{align}

E essas densidades correspondem a

\begin{align*}
\theta|\textbf{x},\sigma^2 &\sim \mathcal{N}\left(\frac{\sigma^2}{\sigma^2 + n \tau^2}\theta_0 + \frac{n \tau^2}{\sigma^2 + n \tau^2}\bar{x} , \frac{\sigma^2\tau^2}{\sigma^2 + n \tau^2} \right)\\
\sigma^2 | \textbf{x}, \theta &\sim \mathcal{IG}\left(\frac{n}{2}+a, \frac{1}{2}\sum_i (x_i - \theta)^2 + b \right)
\end{align*}

O valor de $\bar{x}$ é dado.

```{r}
x     <- c(91,504, 557, 609, 693, 727, 764, 803, 857, 929, 970, 1043, 1089, 1195, 1384, 1713)
x <- log(x)
xbar <- mean(x)
n     <- length(x)
Nsim  <- 5000

# Hiperparametros
theta0 <- 5
tau2   <- 10
a      <- 3
b      <- 3

sh1   <- (n/2)+a
sigma2 <- rep(0, Nsim)
theta <- rep(0, Nsim)
sigma2[1] <- 1/rgamma(1, shape = a, rate = b)
B <- sigma2[1]/(sigma2[1]+n*tau2)
theta[1] <- rnorm(1, m = B*theta0+(1-B)*xbar, sd = sqrt(tau2*B))

for (i in 2:Nsim){
  B <- sigma2[i-1]/(sigma2[i-1]+n*tau2)
  theta[i] <- rnorm(1, m = B*theta0 + (1-B)*xbar, sd = sqrt(tau2 * B))
  ra1 <- (1/2)*(sum((x-theta[i])^2))+B
  sigma2[i] <- 1/rgamma(1, shape=sh1, rate = ra1)
}


cores <- brewer.pal(6, "Dark2")
cores2 <- brewer.pal(10, "Paired")
cadeiadf <- data.frame(seq(5.5, 7.5, length.out = Nsim), theta, seq(0.4, 1.8, length.out = Nsim), sigma2)
names(cadeiadf) <- c("X1", "theta", "X2", "sigma2")

p1 <- ggplot(cadeiadf, aes(x=theta)) + 
    geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
      binwidth=.05, fill = cores[3], colour = cores[3], alpha=0.5)+
  labs(title= TeX('$\\theta - Simulado'), y = "", x= TeX('$\\theta$'), color = "Variável") +
    theme(plot.title=element_text(size = 12),
              text=element_text(size = 12),
              axis.text.x=element_text(colour="black", size = 10),
              axis.text.y=element_text(colour="black", size = 10),
              panel.background = element_blank(),
              panel.grid.major = element_line(colour = "gray"),
              panel.grid.minor = element_line(),
              panel.border = element_rect(colour = "black", fill = NA))
p1 <- p1 + geom_vline(aes(xintercept=mean(theta)),
            color="purple", linetype="dashed", size=1) + annotate("text", x = 7.5, y = 1, label = paste0("Média dos\n valores simulados\n", round(mean(theta),4)), size = 2.5)

p2<- ggplot(cadeiadf, aes(x=sigma2)) + 
    geom_histogram(aes(y=..density..),      # Histogram with density instead of count on y-axis
      binwidth=.05, fill = cores[1], colour = cores[1], alpha=0.5)+
  labs(title= TeX('$\\sigma^2 - Simulado$'), y = "", x= TeX('$\\sigma^2$'), color = "Variável") +
    theme(plot.title=element_text(size = 12),
              text=element_text(size = 12),
              axis.text.x=element_text(colour="black", size = 10),
              axis.text.y=element_text(colour="black", size = 10),
              panel.background = element_blank(),
              panel.grid.major = element_line(colour = "gray"),
              panel.grid.minor = element_line(),
              panel.border = element_rect(colour = "black", fill = NA))
p2 <- p2 + geom_vline(aes(xintercept=mean(sigma2)),
            color="darkgreen", linetype="dashed", size=1) + annotate("text", x = 0.7, y = 2, label = paste0("Média dos\n valores simulados\n", round(mean(sigma2),4)), size = 2.5)

den <- mean(sigma2)+n*tau2
df2 <- data.frame(seq(5.5,7.5, length.out = 30), dnorm(seq(5.5,7.5, length.out = 30), mean =  (1/den)*mean(sigma2)*theta0 + (1/den)*n*tau2*xbar, sd = sqrt(mean(sigma2)*tau2/den)))
names(df2) <- c("theta", "densidade")

p3 <- ggplot(df2, aes(x=theta, y=densidade)) + 
    geom_bar(stat="identity",
      width=.05, fill = cores[4], colour = cores[4], alpha=0.5)+
  labs(title= TeX('$\\theta - Teórico'), y = "", x= TeX('$\\theta$'), color = "Variável") +
    theme(plot.title=element_text(size = 12),
              text=element_text(size = 12),
              axis.text.x=element_text(colour="black", size = 10),
              axis.text.y=element_text(colour="black", size = 10),
              panel.background = element_blank(),
              panel.grid.major = element_line(colour = "gray"),
              panel.grid.minor = element_line(),
              panel.border = element_rect(colour = "black", fill = NA))
p3 <- p3 + geom_vline(aes(xintercept=(1/den)*mean(sigma2)*theta0 + (1/den)*n*tau2*xbar),
            color="pink", linetype="dashed", size=1) + annotate("text", x = 7, y = 1.5, label = paste0("Média da\n distribuição teórica\n", round((1/den)*mean(sigma2)*theta0 + (1/den)*n*tau2*xbar,4)), size = 2.5)

df3 <- data.frame(seq(0.2,1.8, length.out = 50), dinvgamma(seq(0.2,1.8, length.out = 50), shape = n/2+a, rate = 0.5*sum((x-mean(theta))^2)+b))
names(df3) <- c("sigma2", "densidade")
media <- (0.5*sum((x-mean(theta))^2)+b)/((n/2+a)-1)

p4 <- ggplot(df3, aes(x=sigma2, y=densidade)) + 
    geom_bar(stat="identity",
      width=.03, fill = cores[5], colour = cores[5], alpha=0.5)+
  labs(title= TeX('$\\sigma^2 - Teórico'), y = "", x= TeX('$\\sigma^2$'), color = "Variável") +
    theme(plot.title=element_text(size = 12),
              text=element_text(size = 12),
              axis.text.x=element_text(colour="black", size = 10),
              axis.text.y=element_text(colour="black", size = 10),
              panel.background = element_blank(),
              panel.grid.major = element_line(colour = "gray"),
              panel.grid.minor = element_line(),
              panel.border = element_rect(colour = "black", fill = NA))
p4 <- p4 + geom_vline(aes(xintercept=media),
            color="darkgreen", linetype="dashed", size=1) + annotate("text", x = 1, y = 2, label = paste0("Média da\n distribuição teórica\n", round(media,4)), size = 2.5)

grid.arrange(p1, p2, p3, p4, ncol = 2, nrow = 2)


```

# Referências


